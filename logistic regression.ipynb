{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    text=text.lower()\n",
    "    text=re.sub(r'\\d+','',text)\n",
    "    text=text.translate(str.maketrans('','',string.punctuation))\n",
    "    text=text.split()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weight(n_feature):\n",
    "    \n",
    "    weight=np.zeros(n_feature)\n",
    "    bias=0\n",
    "    \n",
    "    return weight,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x,y,y_pred):\n",
    "    \n",
    "    m=x.shape[1]\n",
    "    dw=(1/m)*np.dot(x.T,(y_pred-y))\n",
    "    db=(1/m)*np.sum(y_pred-y)\n",
    "    \n",
    "    return dw,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, y_pred):\n",
    "\n",
    "    m = len(y)\n",
    "    loss = -(1 / m) * np.sum(y * np.log(y_pred + 1e-9) + (1 - y) * np.log(1 - y_pred + 1e-9))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,y,learning_rate=0.01,iteration=1000):\n",
    "    \n",
    "    n_feature=x.shape[1]\n",
    "    weight,bias=initialize_weight(n_feature)\n",
    "    \n",
    "    for i in range(iteration):\n",
    "        linear_model=np.dot(x,weight)+bias\n",
    "        y_pred=sigmoid(linear_model)\n",
    "        \n",
    "        dw,db=compute_gradient(x,y,y_pred)\n",
    "        \n",
    "        weight-=learning_rate*dw\n",
    "        bias-=learning_rate*db\n",
    "        \n",
    "        \n",
    "    return weight,bias\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,weight,bias,threshold=0.3):\n",
    "    \n",
    "    linear_model=np.dot(x,weight)+bias\n",
    "    y_pred=sigmoid(linear_model)\n",
    "    \n",
    "    return (y_pred>=threshold).astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/kamal/Downloads/email.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Category\"]=df[\"Category\"].map({'ham':0,'spam':1})\n",
    "df[\"Message\"]=df[\"Message\"].apply(preprocess)\n",
    "df[\"Message\"] = df[\"Message\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else x) #converting list into string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(ngram_range=(1,2),stop_words='english',max_features=2000)\n",
    "x=vectorizer.fit_transform(df[\"Message\"]).toarray()\n",
    "y=df[\"Category\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in X_train: 0\n",
      "NaN values in y_train: 1\n",
      "Infinite values in X_train: 0\n",
      "Infinite values in y_train: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN values in X_train:\", np.isnan(x_train).sum())\n",
    "print(\"NaN values in y_train:\", np.isnan(y_train).sum())\n",
    "\n",
    "print(\"Infinite values in X_train:\", np.isinf(x_train).sum())\n",
    "print(\"Infinite values in y_train:\", np.isinf(y_train).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"mean\")  \n",
    "y_train = imputer.fit_transform(y_train.reshape(-1, 1)) \n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_train = y_train.astype(int)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)  \n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in y_test: Counter({0: 3868, 1: 1934})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"Class distribution in y_test:\", Counter(y_train_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight,bias=train(x_train_resampled,y_train_resampled,learning_rate=0.1,iteration=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=predict(x_test,weight,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9480\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "print(f\"Accuracy:{accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "your_message = [\"Congratulations! You won a free iPhone. Click here to claim.\"]  \n",
    "processed=preprocess(your_message[0])\n",
    "vectorized=vectorizer.transform([\" \".join(processed)])\n",
    "prediction=predict(vectorized.toarray(),weight,bias)\n",
    "print(\"spam\" if prediction[0]==1 else \"ham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.95      0.97       958\n",
      "         1.0       0.75      0.96      0.84       157\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.87      0.95      0.90      1115\n",
      "weighted avg       0.96      0.95      0.95      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
